{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fd18fc-7fae-4289-b27c-34b86b49ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_dataset, TrainDataset, EvalDataset ,TestDataset \n",
    "from evaluation import Eval_MR\n",
    "from torch.utils.data import DataLoader\n",
    "from model import TransE\n",
    "import torch\n",
    "import numpy as np \n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd \n",
    "import math \n",
    "\n",
    "GPU = True\n",
    "EPOCHS_PER_SEED = 5\n",
    "LR = 0.01\n",
    "LR_DECAY_EPOCH = 5\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optim, decay):\n",
    "    for param_group in optim.param_groups:\n",
    "        param_group['lr'] *= decay\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def __init__(self, data_name):\n",
    "        self.dataset = get_dataset(data_name)\n",
    "        self.n_entities = self.dataset.n_entities\n",
    "        self.n_relations = self.dataset.n_relations\n",
    "\n",
    "    def prepareData(self):\n",
    "        print(\"Perpare dataloader\")\n",
    "        self.train = TrainDataset(self.dataset)\n",
    "        self.trainloader = None\n",
    "        self.valid = EvalDataset(self.dataset)\n",
    "        self.validloader = DataLoader(self.valid, batch_size=self.valid.n_triples, shuffle=False)\n",
    "        self.test = TestDataset(self.dataset)\n",
    "        self.testloader = DataLoader(self.test, batch_size=self.test.n_triples, shuffle=False)\n",
    "\n",
    "    def prepareModel(self):\n",
    "        print(\"Perpare model\")\n",
    "        self.model = TransE(self.n_entities, self.n_relations, embDim=100)\n",
    "        if GPU:\n",
    "            self.model.cuda()\n",
    "\n",
    "    def saveModel(self):\n",
    "        pickle.dump(self.model.get_emb_weights(), open('emb_weight_20220125.pkl', 'wb'))\n",
    "\n",
    "    def fit(self):\n",
    "        optim = torch.optim.Adam(self.model.parameters(), lr=LR)\n",
    "        minLoss = float(\"inf\")\n",
    "        bestMR = float(\"inf\")\n",
    "        GlobalEpoch = 0\n",
    "        for seed in range(100):\n",
    "            print(f\"# Using seed: {seed}\")\n",
    "            self.train.regenerate_neg_samples(seed=seed)\n",
    "            self.trainloader = DataLoader(self.train, batch_size=1024, shuffle=True, num_workers=4)\n",
    "            for epoch in range(EPOCHS_PER_SEED):\n",
    "                GlobalEpoch += 1\n",
    "                for sample in self.trainloader:\n",
    "                    if GPU:\n",
    "                        pos_triples = torch.LongTensor(sample['pos_triples']).cuda()\n",
    "                        neg_triples = torch.LongTensor(sample['neg_triples']).cuda()\n",
    "                    else:\n",
    "                        pos_triples = torch.LongTensor(sample['pos_triples'])\n",
    "                        neg_triples = torch.LongTensor(sample['neg_triples'])\n",
    "\n",
    "                    self.model.normal_emb()\n",
    "\n",
    "                    loss = self.model(pos_triples, neg_triples)\n",
    "                    if GPU:\n",
    "                        lossVal = loss.cpu().item()\n",
    "                    else:\n",
    "                        lossVal = loss.item()\n",
    "\n",
    "                    optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "\n",
    "                    if minLoss > lossVal:\n",
    "                        minLoss = lossVal\n",
    "                MR = Eval_MR(self.validloader, \"L2\", **self.model.get_emb_weights())\n",
    "                if MR < bestMR:\n",
    "                    bestMR = MR\n",
    "                    print('save model ')\n",
    "                    self.saveModel()\n",
    "                    # FILE = \"model.pth\"\n",
    "                    # torch.save(self.model, FILE)\n",
    "                print(f\"Epoch: {epoch + 1}, Total_Train: {GlobalEpoch}, Loss: {lossVal}, minLoss: {minLoss},\"\n",
    "                      f\"MR: {MR}, bestMR: {bestMR}\")\n",
    "                if GlobalEpoch % LR_DECAY_EPOCH == 0:\n",
    "                    adjust_learning_rate(optim, 0.96)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     train = Train('FB15k-237')\n",
    "#     train.prepareData()\n",
    "#     train.prepareModel()\n",
    "#     train.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ced946-0961-4e93-82be-f6a12b64e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train triples...\n",
      "Finished. Read 272115 train triples.\n",
      "Reading valid triples...\n",
      "Finished. Read 17535 valid triples.\n",
      "Reading test triples...\n",
      "Finished. Read 20466 test triples.\n"
     ]
    }
   ],
   "source": [
    "train = Train('FB15k-237')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81da9a9c-f924-4fdc-9236-937ce2fe4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perpare dataloader\n",
      "|Train|: 544230\n",
      "|Valid|: 17535\n",
      "|Test|: 20466\n"
     ]
    }
   ],
   "source": [
    "train.prepareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81417445-aad5-47cb-ad9b-0ae15d8713d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perpare model\n"
     ]
    }
   ],
   "source": [
    "train.prepareModel() # 每次init 模型權重都會變，直接predict 結果皆會不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e7d477-9dbb-4720-a741-f237b4b77405",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Using seed: 0\n",
      "save model \n",
      "Epoch: 1, Total_Train: 1, Loss: 0.47142496705055237, minLoss: 0.456105500459671,MR: 901.8328485885372, bestMR: 901.8328485885372\n",
      "save model \n",
      "Epoch: 2, Total_Train: 2, Loss: 0.2819611132144928, minLoss: 0.2741110920906067,MR: 642.4573139435415, bestMR: 642.4573139435415\n",
      "save model \n",
      "Epoch: 3, Total_Train: 3, Loss: 0.24167214334011078, minLoss: 0.18671663105487823,MR: 537.0740233818078, bestMR: 537.0740233818078\n",
      "save model \n",
      "Epoch: 4, Total_Train: 4, Loss: 0.20377230644226074, minLoss: 0.1531406044960022,MR: 481.182378100941, bestMR: 481.182378100941\n",
      "save model \n",
      "Epoch: 5, Total_Train: 5, Loss: 0.19179368019104004, minLoss: 0.14133676886558533,MR: 458.9081836327345, bestMR: 458.9081836327345\n",
      "# Using seed: 1\n",
      "save model \n",
      "Epoch: 1, Total_Train: 6, Loss: 0.18574243783950806, minLoss: 0.14133676886558533,MR: 418.5479897348161, bestMR: 418.5479897348161\n",
      "save model \n",
      "Epoch: 2, Total_Train: 7, Loss: 0.1855708807706833, minLoss: 0.1350994110107422,MR: 414.57787282577704, bestMR: 414.57787282577704\n",
      "save model \n",
      "Epoch: 3, Total_Train: 8, Loss: 0.14546658098697662, minLoss: 0.1257440447807312,MR: 399.7896777872826, bestMR: 399.7896777872826\n",
      "save model \n",
      "Epoch: 4, Total_Train: 9, Loss: 0.16300944983959198, minLoss: 0.1257440447807312,MR: 391.6975762760194, bestMR: 391.6975762760194\n",
      "Epoch: 5, Total_Train: 10, Loss: 0.15805281698703766, minLoss: 0.1257440447807312,MR: 393.3099515255204, bestMR: 391.6975762760194\n",
      "# Using seed: 2\n",
      "Epoch: 1, Total_Train: 11, Loss: 0.15363606810569763, minLoss: 0.1257440447807312,MR: 392.2851439977189, bestMR: 391.6975762760194\n",
      "save model \n",
      "Epoch: 2, Total_Train: 12, Loss: 0.16319261491298676, minLoss: 0.12375780194997787,MR: 388.7962931280297, bestMR: 388.7962931280297\n",
      "save model \n",
      "Epoch: 3, Total_Train: 13, Loss: 0.1693291962146759, minLoss: 0.1202898919582367,MR: 380.66335899629314, bestMR: 380.66335899629314\n",
      "Epoch: 4, Total_Train: 14, Loss: 0.16149882972240448, minLoss: 0.12013397365808487,MR: 384.68474479612206, bestMR: 380.66335899629314\n",
      "Epoch: 5, Total_Train: 15, Loss: 0.1780526489019394, minLoss: 0.12013397365808487,MR: 386.897120045623, bestMR: 380.66335899629314\n",
      "# Using seed: 3\n",
      "save model \n",
      "Epoch: 1, Total_Train: 16, Loss: 0.1723875105381012, minLoss: 0.12013397365808487,MR: 375.3184488166524, bestMR: 375.3184488166524\n",
      "save model \n",
      "Epoch: 2, Total_Train: 17, Loss: 0.15132153034210205, minLoss: 0.12013397365808487,MR: 374.28189335614485, bestMR: 374.28189335614485\n",
      "Epoch: 3, Total_Train: 18, Loss: 0.14768077433109283, minLoss: 0.11920853704214096,MR: 377.3422868548617, bestMR: 374.28189335614485\n",
      "save model \n",
      "Epoch: 4, Total_Train: 19, Loss: 0.15171703696250916, minLoss: 0.11045991629362106,MR: 372.34587966923294, bestMR: 372.34587966923294\n",
      "save model \n",
      "Epoch: 5, Total_Train: 20, Loss: 0.17513340711593628, minLoss: 0.11045991629362106,MR: 362.201881950385, bestMR: 362.201881950385\n",
      "# Using seed: 4\n",
      "Epoch: 1, Total_Train: 21, Loss: 0.15309354662895203, minLoss: 0.11045991629362106,MR: 363.04727687482176, bestMR: 362.201881950385\n",
      "Epoch: 2, Total_Train: 22, Loss: 0.15945865213871002, minLoss: 0.11045991629362106,MR: 370.54724836042203, bestMR: 362.201881950385\n",
      "Epoch: 3, Total_Train: 23, Loss: 0.1588989794254303, minLoss: 0.11045991629362106,MR: 367.38733960650126, bestMR: 362.201881950385\n",
      "save model \n",
      "Epoch: 4, Total_Train: 24, Loss: 0.18307867646217346, minLoss: 0.11045991629362106,MR: 360.4719133162247, bestMR: 360.4719133162247\n",
      "save model \n",
      "Epoch: 5, Total_Train: 25, Loss: 0.13803158700466156, minLoss: 0.11045991629362106,MR: 360.4278300541774, bestMR: 360.4278300541774\n",
      "# Using seed: 5\n",
      "Epoch: 1, Total_Train: 26, Loss: 0.17305529117584229, minLoss: 0.11045991629362106,MR: 374.73339036213287, bestMR: 360.4278300541774\n",
      "save model \n",
      "Epoch: 2, Total_Train: 27, Loss: 0.15861494839191437, minLoss: 0.10389256477355957,MR: 357.28400342172796, bestMR: 357.28400342172796\n",
      "save model \n",
      "Epoch: 3, Total_Train: 28, Loss: 0.15259262919425964, minLoss: 0.10389256477355957,MR: 352.48172226974623, bestMR: 352.48172226974623\n",
      "Epoch: 4, Total_Train: 29, Loss: 0.17740432918071747, minLoss: 0.10389256477355957,MR: 356.6748217850014, bestMR: 352.48172226974623\n",
      "Epoch: 5, Total_Train: 30, Loss: 0.14262178540229797, minLoss: 0.10389256477355957,MR: 355.1880239520958, bestMR: 352.48172226974623\n",
      "# Using seed: 6\n",
      "Epoch: 1, Total_Train: 31, Loss: 0.18365302681922913, minLoss: 0.10389256477355957,MR: 357.5109210151126, bestMR: 352.48172226974623\n",
      "Epoch: 2, Total_Train: 32, Loss: 0.1491476148366928, minLoss: 0.10389256477355957,MR: 354.6516110635871, bestMR: 352.48172226974623\n",
      "Epoch: 3, Total_Train: 33, Loss: 0.15894943475723267, minLoss: 0.10389256477355957,MR: 352.7525520387796, bestMR: 352.48172226974623\n",
      "save model \n",
      "Epoch: 4, Total_Train: 34, Loss: 0.15880367159843445, minLoss: 0.10389256477355957,MR: 352.0348445965212, bestMR: 352.0348445965212\n",
      "save model \n",
      "Epoch: 5, Total_Train: 35, Loss: 0.16701029241085052, minLoss: 0.10389256477355957,MR: 349.3000285143998, bestMR: 349.3000285143998\n",
      "# Using seed: 7\n",
      "Epoch: 1, Total_Train: 36, Loss: 0.16609196364879608, minLoss: 0.10389256477355957,MR: 351.62395209580836, bestMR: 349.3000285143998\n",
      "Epoch: 2, Total_Train: 37, Loss: 0.139913409948349, minLoss: 0.10389256477355957,MR: 352.59555175363556, bestMR: 349.3000285143998\n",
      "save model \n",
      "Epoch: 3, Total_Train: 38, Loss: 0.13401247560977936, minLoss: 0.10389256477355957,MR: 346.6800684345595, bestMR: 346.6800684345595\n",
      "Epoch: 4, Total_Train: 39, Loss: 0.12434732168912888, minLoss: 0.10295796394348145,MR: 349.8772740233818, bestMR: 346.6800684345595\n",
      "Epoch: 5, Total_Train: 40, Loss: 0.15535031259059906, minLoss: 0.10130791366100311,MR: 354.38431708012547, bestMR: 346.6800684345595\n",
      "# Using seed: 8\n",
      "save model \n",
      "Epoch: 1, Total_Train: 41, Loss: 0.15661807358264923, minLoss: 0.10130791366100311,MR: 341.67601938979186, bestMR: 341.67601938979186\n",
      "save model \n",
      "Epoch: 2, Total_Train: 42, Loss: 0.14728742837905884, minLoss: 0.10130791366100311,MR: 335.5724550898204, bestMR: 335.5724550898204\n",
      "Epoch: 3, Total_Train: 43, Loss: 0.1625431329011917, minLoss: 0.10130791366100311,MR: 340.2566866267465, bestMR: 335.5724550898204\n",
      "Epoch: 4, Total_Train: 44, Loss: 0.1551489382982254, minLoss: 0.10118021816015244,MR: 344.4917023096664, bestMR: 335.5724550898204\n",
      "Epoch: 5, Total_Train: 45, Loss: 0.14998944103717804, minLoss: 0.10118021816015244,MR: 339.99703450242373, bestMR: 335.5724550898204\n",
      "# Using seed: 9\n",
      "Epoch: 1, Total_Train: 46, Loss: 0.14540642499923706, minLoss: 0.10118021816015244,MR: 341.03370402053037, bestMR: 335.5724550898204\n",
      "Epoch: 2, Total_Train: 47, Loss: 0.14880068600177765, minLoss: 0.10118021816015244,MR: 335.59766181921873, bestMR: 335.5724550898204\n",
      "Epoch: 3, Total_Train: 48, Loss: 0.14659254252910614, minLoss: 0.10118021816015244,MR: 341.48537211291705, bestMR: 335.5724550898204\n",
      "Epoch: 4, Total_Train: 49, Loss: 0.15381187200546265, minLoss: 0.10118021816015244,MR: 343.26438551468493, bestMR: 335.5724550898204\n",
      "save model \n",
      "Epoch: 5, Total_Train: 50, Loss: 0.1398700326681137, minLoss: 0.10088403522968292,MR: 332.60450527516394, bestMR: 332.60450527516394\n",
      "# Using seed: 10\n",
      "Epoch: 1, Total_Train: 51, Loss: 0.16027700901031494, minLoss: 0.10088403522968292,MR: 337.6466495580268, bestMR: 332.60450527516394\n",
      "save model \n",
      "Epoch: 2, Total_Train: 52, Loss: 0.14088557660579681, minLoss: 0.10088403522968292,MR: 331.79526660963785, bestMR: 331.79526660963785\n",
      "Epoch: 3, Total_Train: 53, Loss: 0.14822618663311005, minLoss: 0.09687427431344986,MR: 332.51211861990305, bestMR: 331.79526660963785\n",
      "Epoch: 4, Total_Train: 54, Loss: 0.1445949524641037, minLoss: 0.09687427431344986,MR: 332.7476475620188, bestMR: 331.79526660963785\n",
      "Epoch: 5, Total_Train: 55, Loss: 0.16074663400650024, minLoss: 0.09687427431344986,MR: 331.84071856287426, bestMR: 331.79526660963785\n",
      "# Using seed: 11\n",
      "save model \n",
      "Epoch: 1, Total_Train: 56, Loss: 0.1493091583251953, minLoss: 0.09687427431344986,MR: 323.55238095238093, bestMR: 323.55238095238093\n",
      "Epoch: 2, Total_Train: 57, Loss: 0.1545325070619583, minLoss: 0.09687427431344986,MR: 335.7565440547476, bestMR: 323.55238095238093\n",
      "Epoch: 3, Total_Train: 58, Loss: 0.15655529499053955, minLoss: 0.09687427431344986,MR: 326.08177929854577, bestMR: 323.55238095238093\n",
      "Epoch: 4, Total_Train: 59, Loss: 0.14088037610054016, minLoss: 0.09687427431344986,MR: 336.2110635871115, bestMR: 323.55238095238093\n",
      "Epoch: 5, Total_Train: 60, Loss: 0.1418810486793518, minLoss: 0.09687427431344986,MR: 331.1713145138295, bestMR: 323.55238095238093\n",
      "# Using seed: 12\n",
      "Epoch: 1, Total_Train: 61, Loss: 0.170310840010643, minLoss: 0.09687427431344986,MR: 330.8732249786142, bestMR: 323.55238095238093\n",
      "Epoch: 2, Total_Train: 62, Loss: 0.1704190969467163, minLoss: 0.09687427431344986,MR: 329.126375819789, bestMR: 323.55238095238093\n",
      "Epoch: 3, Total_Train: 63, Loss: 0.13950300216674805, minLoss: 0.09687427431344986,MR: 330.7320786997434, bestMR: 323.55238095238093\n",
      "Epoch: 4, Total_Train: 64, Loss: 0.14722703397274017, minLoss: 0.09687427431344986,MR: 334.0963216424294, bestMR: 323.55238095238093\n",
      "Epoch: 5, Total_Train: 65, Loss: 0.13322849571704865, minLoss: 0.09687427431344986,MR: 326.72278300541774, bestMR: 323.55238095238093\n",
      "# Using seed: 13\n",
      "Epoch: 1, Total_Train: 66, Loss: 0.15057887136936188, minLoss: 0.09687427431344986,MR: 326.08189335614486, bestMR: 323.55238095238093\n",
      "Epoch: 2, Total_Train: 67, Loss: 0.1345890313386917, minLoss: 0.09687427431344986,MR: 324.5750213857998, bestMR: 323.55238095238093\n",
      "Epoch: 3, Total_Train: 68, Loss: 0.12935404479503632, minLoss: 0.09687427431344986,MR: 323.77753065297975, bestMR: 323.55238095238093\n",
      "Epoch: 4, Total_Train: 69, Loss: 0.14468182623386383, minLoss: 0.09687427431344986,MR: 324.67459366980324, bestMR: 323.55238095238093\n",
      "Epoch: 5, Total_Train: 70, Loss: 0.1368129700422287, minLoss: 0.09687427431344986,MR: 326.52284003421727, bestMR: 323.55238095238093\n",
      "# Using seed: 14\n",
      "save model \n",
      "Epoch: 1, Total_Train: 71, Loss: 0.15334351360797882, minLoss: 0.09687427431344986,MR: 315.84528086683775, bestMR: 315.84528086683775\n",
      "save model \n",
      "Epoch: 2, Total_Train: 72, Loss: 0.14919544756412506, minLoss: 0.09687427431344986,MR: 310.45543199315654, bestMR: 310.45543199315654\n",
      "Epoch: 3, Total_Train: 73, Loss: 0.14820091426372528, minLoss: 0.09687427431344986,MR: 311.4076988879384, bestMR: 310.45543199315654\n",
      "save model \n",
      "Epoch: 4, Total_Train: 74, Loss: 0.14275848865509033, minLoss: 0.09369324892759323,MR: 310.20108354719133, bestMR: 310.20108354719133\n",
      "Epoch: 5, Total_Train: 75, Loss: 0.1404099315404892, minLoss: 0.09369324892759323,MR: 312.5364128885087, bestMR: 310.20108354719133\n",
      "# Using seed: 15\n",
      "save model \n",
      "Epoch: 1, Total_Train: 76, Loss: 0.14931423962116241, minLoss: 0.09369324892759323,MR: 305.7940690048475, bestMR: 305.7940690048475\n",
      "save model \n",
      "Epoch: 2, Total_Train: 77, Loss: 0.14680223166942596, minLoss: 0.09369324892759323,MR: 304.30875392072994, bestMR: 304.30875392072994\n",
      "Epoch: 3, Total_Train: 78, Loss: 0.14030461013317108, minLoss: 0.09369324892759323,MR: 305.1313373253493, bestMR: 304.30875392072994\n",
      "Epoch: 4, Total_Train: 79, Loss: 0.13684293627738953, minLoss: 0.08686956763267517,MR: 312.24625035643, bestMR: 304.30875392072994\n",
      "Epoch: 5, Total_Train: 80, Loss: 0.16284586489200592, minLoss: 0.08686956763267517,MR: 311.35374964357, bestMR: 304.30875392072994\n",
      "# Using seed: 16\n",
      "Epoch: 1, Total_Train: 81, Loss: 0.12055568397045135, minLoss: 0.08686956763267517,MR: 305.5268890789849, bestMR: 304.30875392072994\n",
      "Epoch: 2, Total_Train: 82, Loss: 0.123540960252285, minLoss: 0.08686956763267517,MR: 311.3490162532079, bestMR: 304.30875392072994\n",
      "Epoch: 3, Total_Train: 83, Loss: 0.14215247333049774, minLoss: 0.08686956763267517,MR: 306.15209580838325, bestMR: 304.30875392072994\n",
      "Epoch: 4, Total_Train: 84, Loss: 0.1316678673028946, minLoss: 0.08686956763267517,MR: 307.55317935557457, bestMR: 304.30875392072994\n",
      "Epoch: 5, Total_Train: 85, Loss: 0.13307751715183258, minLoss: 0.08686956763267517,MR: 310.05560307955517, bestMR: 304.30875392072994\n",
      "# Using seed: 17\n",
      "Epoch: 1, Total_Train: 86, Loss: 0.12470851093530655, minLoss: 0.08686956763267517,MR: 306.4159110350727, bestMR: 304.30875392072994\n",
      "save model \n",
      "Epoch: 2, Total_Train: 87, Loss: 0.11810512840747833, minLoss: 0.08686956763267517,MR: 301.96435700028513, bestMR: 301.96435700028513\n",
      "Epoch: 3, Total_Train: 88, Loss: 0.12459243834018707, minLoss: 0.08686956763267517,MR: 307.5984602224123, bestMR: 301.96435700028513\n",
      "save model \n",
      "Epoch: 4, Total_Train: 89, Loss: 0.12509921193122864, minLoss: 0.08686956763267517,MR: 301.29962931280295, bestMR: 301.29962931280295\n",
      "save model \n",
      "Epoch: 5, Total_Train: 90, Loss: 0.13608267903327942, minLoss: 0.08686956763267517,MR: 300.4822355289421, bestMR: 300.4822355289421\n",
      "# Using seed: 18\n",
      "save model \n",
      "Epoch: 1, Total_Train: 91, Loss: 0.13749346137046814, minLoss: 0.08686956763267517,MR: 297.6571998859424, bestMR: 297.6571998859424\n",
      "Epoch: 2, Total_Train: 92, Loss: 0.1205412819981575, minLoss: 0.08686956763267517,MR: 298.1275163957799, bestMR: 297.6571998859424\n",
      "Epoch: 3, Total_Train: 93, Loss: 0.13592085242271423, minLoss: 0.08686956763267517,MR: 301.6845166809239, bestMR: 297.6571998859424\n",
      "Epoch: 4, Total_Train: 94, Loss: 0.14004145562648773, minLoss: 0.08686956763267517,MR: 300.1088109495295, bestMR: 297.6571998859424\n",
      "Epoch: 5, Total_Train: 95, Loss: 0.12712602317333221, minLoss: 0.08686956763267517,MR: 299.97063016823495, bestMR: 297.6571998859424\n",
      "# Using seed: 19\n",
      "save model \n",
      "Epoch: 1, Total_Train: 96, Loss: 0.13538506627082825, minLoss: 0.08686956763267517,MR: 297.3021956087824, bestMR: 297.3021956087824\n",
      "save model \n",
      "Epoch: 2, Total_Train: 97, Loss: 0.12508149445056915, minLoss: 0.08686956763267517,MR: 295.88554319931563, bestMR: 295.88554319931563\n",
      "save model \n",
      "Epoch: 3, Total_Train: 98, Loss: 0.13015109300613403, minLoss: 0.08686956763267517,MR: 293.9580838323353, bestMR: 293.9580838323353\n",
      "Epoch: 4, Total_Train: 99, Loss: 0.14068278670310974, minLoss: 0.08686956763267517,MR: 299.1668092386655, bestMR: 293.9580838323353\n",
      "Epoch: 5, Total_Train: 100, Loss: 0.1176857277750969, minLoss: 0.08686956763267517,MR: 298.1646991730824, bestMR: 293.9580838323353\n",
      "# Using seed: 20\n",
      "save model \n",
      "Epoch: 1, Total_Train: 101, Loss: 0.14666399359703064, minLoss: 0.08686956763267517,MR: 291.142001710864, bestMR: 291.142001710864\n",
      "save model \n",
      "Epoch: 2, Total_Train: 102, Loss: 0.11463870108127594, minLoss: 0.08686956763267517,MR: 289.61944682064444, bestMR: 289.61944682064444\n",
      "Epoch: 3, Total_Train: 103, Loss: 0.13288092613220215, minLoss: 0.08636099100112915,MR: 296.59344168805245, bestMR: 289.61944682064444\n",
      "Epoch: 4, Total_Train: 104, Loss: 0.11834104359149933, minLoss: 0.08491552621126175,MR: 295.2370687197035, bestMR: 289.61944682064444\n",
      "Epoch: 5, Total_Train: 105, Loss: 0.10185050219297409, minLoss: 0.08226552605628967,MR: 293.71668092386653, bestMR: 289.61944682064444\n",
      "# Using seed: 21\n",
      "save model \n",
      "Epoch: 1, Total_Train: 106, Loss: 0.14314700663089752, minLoss: 0.08226552605628967,MR: 285.1199885942401, bestMR: 285.1199885942401\n",
      "Epoch: 2, Total_Train: 107, Loss: 0.12100610882043839, minLoss: 0.08226552605628967,MR: 288.6185913886513, bestMR: 285.1199885942401\n",
      "Epoch: 3, Total_Train: 108, Loss: 0.13042178750038147, minLoss: 0.08226552605628967,MR: 289.6055888223553, bestMR: 285.1199885942401\n",
      "save model \n",
      "Epoch: 4, Total_Train: 109, Loss: 0.1347639113664627, minLoss: 0.08226552605628967,MR: 284.55848303393213, bestMR: 284.55848303393213\n",
      "Epoch: 5, Total_Train: 110, Loss: 0.12164830416440964, minLoss: 0.08226552605628967,MR: 284.9867122897063, bestMR: 284.55848303393213\n",
      "# Using seed: 22\n",
      "save model \n",
      "Epoch: 1, Total_Train: 111, Loss: 0.12386693805456161, minLoss: 0.08226552605628967,MR: 283.29039064727687, bestMR: 283.29039064727687\n",
      "Epoch: 2, Total_Train: 112, Loss: 0.1172470822930336, minLoss: 0.08226552605628967,MR: 284.27715996578274, bestMR: 283.29039064727687\n",
      "Epoch: 3, Total_Train: 113, Loss: 0.11994665116071701, minLoss: 0.08226552605628967,MR: 288.6315939549472, bestMR: 283.29039064727687\n",
      "Epoch: 4, Total_Train: 114, Loss: 0.15022119879722595, minLoss: 0.08226552605628967,MR: 291.86096378671226, bestMR: 283.29039064727687\n",
      "Epoch: 5, Total_Train: 115, Loss: 0.11662355065345764, minLoss: 0.08001229166984558,MR: 290.155745651554, bestMR: 283.29039064727687\n",
      "# Using seed: 23\n",
      "save model \n",
      "Epoch: 1, Total_Train: 116, Loss: 0.13549675047397614, minLoss: 0.08001229166984558,MR: 280.62104362703167, bestMR: 280.62104362703167\n",
      "Epoch: 2, Total_Train: 117, Loss: 0.11597993224859238, minLoss: 0.08001229166984558,MR: 284.91040775591676, bestMR: 280.62104362703167\n",
      "Epoch: 3, Total_Train: 118, Loss: 0.13583099842071533, minLoss: 0.07952278107404709,MR: 281.6313658397491, bestMR: 280.62104362703167\n",
      "Epoch: 4, Total_Train: 119, Loss: 0.12281926721334457, minLoss: 0.07952278107404709,MR: 283.12095808383236, bestMR: 280.62104362703167\n",
      "Epoch: 5, Total_Train: 120, Loss: 0.11790058016777039, minLoss: 0.07952278107404709,MR: 285.25286569717707, bestMR: 280.62104362703167\n",
      "# Using seed: 24\n",
      "save model \n",
      "Epoch: 1, Total_Train: 121, Loss: 0.13230453431606293, minLoss: 0.07952278107404709,MR: 274.9495295124038, bestMR: 274.9495295124038\n",
      "Epoch: 2, Total_Train: 122, Loss: 0.13219021260738373, minLoss: 0.07952278107404709,MR: 278.1013401767893, bestMR: 274.9495295124038\n",
      "Epoch: 3, Total_Train: 123, Loss: 0.12630456686019897, minLoss: 0.07952278107404709,MR: 279.3625891074993, bestMR: 274.9495295124038\n",
      "Epoch: 4, Total_Train: 124, Loss: 0.11094410717487335, minLoss: 0.07952278107404709,MR: 282.6180781294554, bestMR: 274.9495295124038\n",
      "Epoch: 5, Total_Train: 125, Loss: 0.11278913170099258, minLoss: 0.07952278107404709,MR: 280.84288565725694, bestMR: 274.9495295124038\n",
      "# Using seed: 25\n",
      "save model \n",
      "Epoch: 1, Total_Train: 126, Loss: 0.13277216255664825, minLoss: 0.07952278107404709,MR: 274.61790704305673, bestMR: 274.61790704305673\n",
      "Epoch: 2, Total_Train: 127, Loss: 0.11466684937477112, minLoss: 0.07952278107404709,MR: 277.79469632164245, bestMR: 274.61790704305673\n",
      "Epoch: 3, Total_Train: 128, Loss: 0.12705731391906738, minLoss: 0.07952278107404709,MR: 276.61305959509554, bestMR: 274.61790704305673\n",
      "Epoch: 4, Total_Train: 129, Loss: 0.12830977141857147, minLoss: 0.07952278107404709,MR: 279.8372398061021, bestMR: 274.61790704305673\n",
      "Epoch: 5, Total_Train: 130, Loss: 0.1326138973236084, minLoss: 0.07952278107404709,MR: 281.10208155118335, bestMR: 274.61790704305673\n",
      "# Using seed: 26\n",
      "Epoch: 1, Total_Train: 131, Loss: 0.1258310079574585, minLoss: 0.07952278107404709,MR: 274.7320786997434, bestMR: 274.61790704305673\n",
      "Epoch: 2, Total_Train: 132, Loss: 0.1273120790719986, minLoss: 0.07952278107404709,MR: 277.9400627316795, bestMR: 274.61790704305673\n",
      "Epoch: 3, Total_Train: 133, Loss: 0.12385360896587372, minLoss: 0.07952278107404709,MR: 277.05856857713144, bestMR: 274.61790704305673\n",
      "Epoch: 4, Total_Train: 134, Loss: 0.12465149909257889, minLoss: 0.07952278107404709,MR: 276.7636726546906, bestMR: 274.61790704305673\n",
      "Epoch: 5, Total_Train: 135, Loss: 0.12551622092723846, minLoss: 0.07952278107404709,MR: 278.7216994582264, bestMR: 274.61790704305673\n",
      "# Using seed: 27\n",
      "save model \n",
      "Epoch: 1, Total_Train: 136, Loss: 0.13346828520298004, minLoss: 0.07952278107404709,MR: 272.59327060165384, bestMR: 272.59327060165384\n",
      "save model \n",
      "Epoch: 2, Total_Train: 137, Loss: 0.1282055675983429, minLoss: 0.07952278107404709,MR: 272.37428001140574, bestMR: 272.37428001140574\n",
      "Epoch: 3, Total_Train: 138, Loss: 0.11811576038599014, minLoss: 0.07952278107404709,MR: 278.298374679213, bestMR: 272.37428001140574\n",
      "Epoch: 4, Total_Train: 139, Loss: 0.1134868711233139, minLoss: 0.07733305543661118,MR: 279.02754491017964, bestMR: 272.37428001140574\n",
      "Epoch: 5, Total_Train: 140, Loss: 0.11921513080596924, minLoss: 0.07733305543661118,MR: 280.37245508982033, bestMR: 272.37428001140574\n",
      "# Using seed: 28\n",
      "Epoch: 1, Total_Train: 141, Loss: 0.09909846633672714, minLoss: 0.07733305543661118,MR: 273.20946678072426, bestMR: 272.37428001140574\n",
      "save model \n",
      "Epoch: 2, Total_Train: 142, Loss: 0.09589510411024094, minLoss: 0.07733305543661118,MR: 271.6051896207585, bestMR: 271.6051896207585\n",
      "Epoch: 3, Total_Train: 143, Loss: 0.10005542635917664, minLoss: 0.07733305543661118,MR: 273.51183347590535, bestMR: 271.6051896207585\n",
      "Epoch: 4, Total_Train: 144, Loss: 0.12071733176708221, minLoss: 0.07733305543661118,MR: 272.74205873966355, bestMR: 271.6051896207585\n",
      "Epoch: 5, Total_Train: 145, Loss: 0.11764132231473923, minLoss: 0.07733305543661118,MR: 275.98848018249214, bestMR: 271.6051896207585\n",
      "# Using seed: 29\n",
      "save model \n",
      "Epoch: 1, Total_Train: 146, Loss: 0.12579481303691864, minLoss: 0.07733305543661118,MR: 267.1594525235244, bestMR: 267.1594525235244\n",
      "Epoch: 2, Total_Train: 147, Loss: 0.11866635084152222, minLoss: 0.07729630172252655,MR: 268.28919304248643, bestMR: 267.1594525235244\n",
      "Epoch: 3, Total_Train: 148, Loss: 0.11571267247200012, minLoss: 0.07729630172252655,MR: 271.949871685201, bestMR: 267.1594525235244\n",
      "Epoch: 4, Total_Train: 149, Loss: 0.12123064696788788, minLoss: 0.0710739940404892,MR: 273.7170801254634, bestMR: 267.1594525235244\n",
      "Epoch: 5, Total_Train: 150, Loss: 0.10941841453313828, minLoss: 0.0710739940404892,MR: 272.80604505275164, bestMR: 267.1594525235244\n",
      "# Using seed: 30\n",
      "Epoch: 1, Total_Train: 151, Loss: 0.13060955703258514, minLoss: 0.0710739940404892,MR: 268.93561448531506, bestMR: 267.1594525235244\n",
      "Epoch: 2, Total_Train: 152, Loss: 0.09957165271043777, minLoss: 0.0710739940404892,MR: 271.22691759338466, bestMR: 267.1594525235244\n",
      "Epoch: 3, Total_Train: 153, Loss: 0.10347869992256165, minLoss: 0.0710739940404892,MR: 269.5721129170231, bestMR: 267.1594525235244\n",
      "Epoch: 4, Total_Train: 154, Loss: 0.11659291386604309, minLoss: 0.0710739940404892,MR: 273.52700313658397, bestMR: 267.1594525235244\n",
      "Epoch: 5, Total_Train: 155, Loss: 0.10183404386043549, minLoss: 0.0710739940404892,MR: 274.93749643570004, bestMR: 267.1594525235244\n",
      "# Using seed: 31\n",
      "save model \n",
      "Epoch: 1, Total_Train: 156, Loss: 0.11220739781856537, minLoss: 0.0710739940404892,MR: 265.47681779298546, bestMR: 265.47681779298546\n",
      "save model \n",
      "Epoch: 2, Total_Train: 157, Loss: 0.11949220299720764, minLoss: 0.0710739940404892,MR: 263.686626746507, bestMR: 263.686626746507\n",
      "Epoch: 3, Total_Train: 158, Loss: 0.11526315659284592, minLoss: 0.0710739940404892,MR: 267.57102936983176, bestMR: 263.686626746507\n",
      "Epoch: 4, Total_Train: 159, Loss: 0.11082347482442856, minLoss: 0.0710739940404892,MR: 267.4621613915027, bestMR: 263.686626746507\n",
      "Epoch: 5, Total_Train: 160, Loss: 0.11950532346963882, minLoss: 0.0710739940404892,MR: 266.7391502708868, bestMR: 263.686626746507\n",
      "# Using seed: 32\n",
      "save model \n",
      "Epoch: 1, Total_Train: 161, Loss: 0.11465314775705338, minLoss: 0.0710739940404892,MR: 260.0596521243228, bestMR: 260.0596521243228\n",
      "Epoch: 2, Total_Train: 162, Loss: 0.11254663020372391, minLoss: 0.0710739940404892,MR: 262.5835186769319, bestMR: 260.0596521243228\n",
      "Epoch: 3, Total_Train: 163, Loss: 0.10905943810939789, minLoss: 0.0710739940404892,MR: 269.04277159965784, bestMR: 260.0596521243228\n",
      "Epoch: 4, Total_Train: 164, Loss: 0.11185480654239655, minLoss: 0.0710739940404892,MR: 268.2341602509267, bestMR: 260.0596521243228\n",
      "Epoch: 5, Total_Train: 165, Loss: 0.11304175853729248, minLoss: 0.0710739940404892,MR: 270.8222412318221, bestMR: 260.0596521243228\n",
      "# Using seed: 33\n",
      "Epoch: 1, Total_Train: 166, Loss: 0.11350811272859573, minLoss: 0.0710739940404892,MR: 263.03929284288563, bestMR: 260.0596521243228\n",
      "Epoch: 2, Total_Train: 167, Loss: 0.11113940179347992, minLoss: 0.0710739940404892,MR: 262.6419731964642, bestMR: 260.0596521243228\n",
      "Epoch: 3, Total_Train: 168, Loss: 0.12926803529262543, minLoss: 0.0710739940404892,MR: 266.8504704875962, bestMR: 260.0596521243228\n",
      "Epoch: 4, Total_Train: 169, Loss: 0.1060376912355423, minLoss: 0.0710739940404892,MR: 265.8295979469632, bestMR: 260.0596521243228\n",
      "Epoch: 5, Total_Train: 170, Loss: 0.13771572709083557, minLoss: 0.0710739940404892,MR: 266.4164813230681, bestMR: 260.0596521243228\n",
      "# Using seed: 34\n",
      "Epoch: 1, Total_Train: 171, Loss: 0.11216256022453308, minLoss: 0.0710739940404892,MR: 261.31228970630167, bestMR: 260.0596521243228\n",
      "Epoch: 2, Total_Train: 172, Loss: 0.11987734586000443, minLoss: 0.0710739940404892,MR: 262.853378956373, bestMR: 260.0596521243228\n",
      "Epoch: 3, Total_Train: 173, Loss: 0.08725161850452423, minLoss: 0.0710739940404892,MR: 260.64368406045054, bestMR: 260.0596521243228\n",
      "Epoch: 4, Total_Train: 174, Loss: 0.10102979838848114, minLoss: 0.0710739940404892,MR: 264.52540633019674, bestMR: 260.0596521243228\n",
      "Epoch: 5, Total_Train: 175, Loss: 0.11061500757932663, minLoss: 0.0710739940404892,MR: 263.37428001140574, bestMR: 260.0596521243228\n",
      "# Using seed: 35\n",
      "save model \n",
      "Epoch: 1, Total_Train: 176, Loss: 0.11857856065034866, minLoss: 0.0710739940404892,MR: 257.2459652124323, bestMR: 257.2459652124323\n",
      "Epoch: 2, Total_Train: 177, Loss: 0.10656803101301193, minLoss: 0.0710739940404892,MR: 259.57063016823497, bestMR: 257.2459652124323\n",
      "Epoch: 3, Total_Train: 178, Loss: 0.1055370345711708, minLoss: 0.0710739940404892,MR: 259.739378386085, bestMR: 257.2459652124323\n",
      "Epoch: 4, Total_Train: 179, Loss: 0.11466032266616821, minLoss: 0.0710739940404892,MR: 262.1593384659253, bestMR: 257.2459652124323\n",
      "Epoch: 5, Total_Train: 180, Loss: 0.10785235464572906, minLoss: 0.0710739940404892,MR: 264.4581693755346, bestMR: 257.2459652124323\n",
      "# Using seed: 36\n",
      "save model \n",
      "Epoch: 1, Total_Train: 181, Loss: 0.11438356339931488, minLoss: 0.0710739940404892,MR: 254.5287140005703, bestMR: 254.5287140005703\n",
      "Epoch: 2, Total_Train: 182, Loss: 0.10592269897460938, minLoss: 0.0710739940404892,MR: 256.73162246934703, bestMR: 254.5287140005703\n",
      "Epoch: 3, Total_Train: 183, Loss: 0.09620189666748047, minLoss: 0.0710739940404892,MR: 259.5440547476476, bestMR: 254.5287140005703\n",
      "Epoch: 4, Total_Train: 184, Loss: 0.10507281124591827, minLoss: 0.0710739940404892,MR: 260.2096378671229, bestMR: 254.5287140005703\n",
      "Epoch: 5, Total_Train: 185, Loss: 0.11440835893154144, minLoss: 0.0710739940404892,MR: 260.25623039635013, bestMR: 254.5287140005703\n",
      "# Using seed: 37\n",
      "save model \n",
      "Epoch: 1, Total_Train: 186, Loss: 0.11246342957019806, minLoss: 0.0710739940404892,MR: 251.1240376390077, bestMR: 251.1240376390077\n",
      "Epoch: 2, Total_Train: 187, Loss: 0.11438269168138504, minLoss: 0.0710739940404892,MR: 256.11901910464786, bestMR: 251.1240376390077\n",
      "Epoch: 3, Total_Train: 188, Loss: 0.10740688443183899, minLoss: 0.0710739940404892,MR: 254.15642999714856, bestMR: 251.1240376390077\n",
      "Epoch: 4, Total_Train: 189, Loss: 0.11348585784435272, minLoss: 0.0710739940404892,MR: 256.47932706016536, bestMR: 251.1240376390077\n",
      "Epoch: 5, Total_Train: 190, Loss: 0.10625020414590836, minLoss: 0.0710739940404892,MR: 256.56863416025095, bestMR: 251.1240376390077\n",
      "# Using seed: 38\n",
      "save model \n",
      "Epoch: 1, Total_Train: 191, Loss: 0.1182669922709465, minLoss: 0.0710739940404892,MR: 249.3211861990305, bestMR: 249.3211861990305\n",
      "Epoch: 2, Total_Train: 192, Loss: 0.11955522000789642, minLoss: 0.0710739940404892,MR: 250.64773310521812, bestMR: 249.3211861990305\n",
      "Epoch: 3, Total_Train: 193, Loss: 0.09387237578630447, minLoss: 0.0710739940404892,MR: 251.39469632164244, bestMR: 249.3211861990305\n",
      "Epoch: 4, Total_Train: 194, Loss: 0.11234953254461288, minLoss: 0.0710739940404892,MR: 254.01248930710008, bestMR: 249.3211861990305\n",
      "Epoch: 5, Total_Train: 195, Loss: 0.10310042649507523, minLoss: 0.07075945287942886,MR: 254.53270601653836, bestMR: 249.3211861990305\n",
      "# Using seed: 39\n",
      "save model \n",
      "Epoch: 1, Total_Train: 196, Loss: 0.104862280189991, minLoss: 0.07075945287942886,MR: 248.08582834331338, bestMR: 248.08582834331338\n",
      "Epoch: 2, Total_Train: 197, Loss: 0.11447060853242874, minLoss: 0.07075945287942886,MR: 250.6581123467351, bestMR: 248.08582834331338\n",
      "Epoch: 3, Total_Train: 198, Loss: 0.09208507835865021, minLoss: 0.07062936574220657,MR: 252.6873110921015, bestMR: 248.08582834331338\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-dd061e189ed9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-fcf9c14fe296>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mminLoss\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlossVal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                         \u001b[0mminLoss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossVal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mMR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEval_MR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"L2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_emb_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mMR\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbestMR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                     \u001b[0mbestMR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Tim\\transE\\TransE-Pytorch-Implementation\\evaluation.py\u001b[0m in \u001b[0;36mEval_MR\u001b[1;34m(evalloader, simMeasure, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'e_emb'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'r_emb'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0msimScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'e_emb'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimMeasure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalRank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimScore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mR\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Tim\\transE\\TransE-Pytorch-Implementation\\evaluation.py\u001b[0m in \u001b[0;36mcalSimilarity\u001b[1;34m(exptail, e_emb, simMeasure)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0msimScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mexp_e\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexptail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_e\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0me_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0msimScore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b5ec9-6934-4d04-a94a-f1e5935cdd7b",
   "metadata": {},
   "source": [
    "# predict 從這裡開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72897e07-ca52-418f-8cdf-546c4b531f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataloader\n",
    "def Eval_MR2(evalloader: dataloader, #simMeasure,\n",
    "             **kwargs\n",
    "            ):\n",
    "    R = 0\n",
    "    N = 0\n",
    "    for triples in evalloader:\n",
    "        triples = triples.numpy()\n",
    "        h0, r0, t0 = triples[:, 0], triples[:, 1], triples[:, 2]\n",
    "        h = np.take(kwargs['e_emb'], indices=h0, axis=0) # len(h) = 17535\n",
    "        r = np.take(kwargs['r_emb'], indices=r0, axis=0) # len(r) = 17535\n",
    "        t = np.take(kwargs['e_emb'], indices=t0, axis=0) # len(t) = 17535\n",
    "        # simScore = calSimilarity(h+r, kwargs['e_emb'], simMeasure)\n",
    "        # ranks = calRank(simScore, t)\n",
    "        # R += np.sum(ranks)\n",
    "        # N += ranks.shape[0]\n",
    "    return h , r ,t ,[h0,r0,t0]#,R / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1ee3a4-473c-40eb-8625-b16fb2c446b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "with open('emb_weight_20220125.pkl', 'rb') as f:\n",
    "    get_emb_weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f68a49b1-8fa0-440d-a27e-618583932e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1 , r1 ,t1  = Eval_MR2(train.testloader,  **train.model.get_emb_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761a228a-706f-4398-8ded-a67653a2b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "h , r ,t ,index_ = Eval_MR2(train.testloader,  **get_emb_weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20b94a7-7a8a-407a-bd34-6eaa47eedf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07764608,  0.01966429,  0.06293502, ...,  0.00037094,\n",
       "        -0.06863769, -0.165984  ],\n",
       "       [-0.08491039,  0.10034832,  0.09443039, ..., -0.12913279,\n",
       "        -0.12995197,  0.10308704],\n",
       "       [-0.12658772,  0.11487907,  0.08221328, ...,  0.05396236,\n",
       "        -0.04265753,  0.11657944],\n",
       "       ...,\n",
       "       [ 0.01783859,  0.00921735, -0.12230428, ...,  0.19053403,\n",
       "         0.11407951, -0.04722907],\n",
       "       [ 0.01779311, -0.08040216,  0.03185505, ..., -0.07723701,\n",
       "         0.17749844, -0.05336093],\n",
       "       [-0.10716069,  0.08135753,  0.09835683, ...,  0.08480228,\n",
       "        -0.08312382,  0.08235199]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae58728-823d-46dc-a2d6-8081e9b9131c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03153617, -0.14209162, -0.2708895 , ...,  0.26972923,\n",
       "        -0.14447203,  0.02785578],\n",
       "       [-0.03264477, -0.24892859, -0.26211855, ...,  0.21051855,\n",
       "        -0.17860016,  0.09617757],\n",
       "       [-0.27369118, -0.19407567,  0.04544272, ..., -0.04968257,\n",
       "        -0.09847382,  0.07431498],\n",
       "       ...,\n",
       "       [-0.10441644,  0.24610111,  0.2785821 , ..., -0.20137322,\n",
       "         0.12099136, -0.04000435],\n",
       "       [-0.29845864, -0.25763604, -0.10449464, ...,  0.1126167 ,\n",
       "         0.05744866, -0.22404554],\n",
       "       [-0.24515048, -0.00726994, -0.21764009, ...,  0.20149611,\n",
       "        -0.0949312 ,  0.28120804]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e4b88-27f7-4a67-89a3-abe0bc43cd87",
   "metadata": {},
   "source": [
    "# None 值 predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d31665-4ecf-4edf-9f4b-67532a589b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "with open('emb_weight_20220125.pkl', 'rb') as f:\n",
    "    get_emb_weights = pickle.load(f)\n",
    "def get_e_emb(indices , **kwargs\n",
    "            ): # 輸入entity編碼後回傳結果\n",
    "    r = np.take(kwargs['e_emb'], indices=indices, axis=0)\n",
    "    return r\n",
    "def get_r_emb(indices , **kwargs\n",
    "            ): # 輸入relation編碼後回傳結果\n",
    "    r = np.take(kwargs['r_emb'], indices=indices, axis=0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b707ff8b-3de8-4202-b3e8-b20c48bbcea8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11687996,  0.17215681, -0.06266562, -0.08467472,  0.09452362,\n",
       "       -0.06867414, -0.11942425,  0.14816137, -0.09255349,  0.14969264,\n",
       "        0.02969402,  0.08838042, -0.07064307,  0.1032944 , -0.08379799,\n",
       "       -0.09309568, -0.08961347,  0.04722863,  0.10178427, -0.04194168,\n",
       "       -0.08710565, -0.08487288,  0.07398315,  0.0674083 , -0.02656736,\n",
       "       -0.11092649,  0.01499554, -0.00128763,  0.10285509, -0.14714028,\n",
       "       -0.11825156,  0.05726233,  0.11264145, -0.02677056, -0.11430357,\n",
       "        0.10821625,  0.08950803, -0.12698469, -0.07415128, -0.06277288,\n",
       "       -0.05494906, -0.00508549, -0.10830335,  0.12483893,  0.1147564 ,\n",
       "        0.11925494, -0.10688307, -0.1036757 , -0.09014288,  0.11465847,\n",
       "       -0.13576616, -0.10710268,  0.13876052, -0.09632992,  0.01957146,\n",
       "       -0.08852017, -0.10227995, -0.14775316,  0.1485116 ,  0.00161598,\n",
       "       -0.0022591 , -0.08747811, -0.13465168, -0.05597105,  0.05682161,\n",
       "        0.1384316 ,  0.13115364, -0.13857238,  0.14383332,  0.12815548,\n",
       "       -0.08153161,  0.13264266,  0.01476918,  0.05895534,  0.15444012,\n",
       "       -0.10177042, -0.04991766,  0.17305033, -0.13457438, -0.11541579,\n",
       "       -0.12751687, -0.11671401,  0.04891598, -0.04042487, -0.12063804,\n",
       "        0.06153609,  0.00183714,  0.12955844,  0.14426006,  0.0662414 ,\n",
       "       -0.10763662,  0.1103309 ,  0.07485359,  0.10076961, -0.11462256,\n",
       "       -0.02752499, -0.10472868,  0.06895128,  0.12265813, -0.09057489],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None 值 entity會有權重\n",
    "get_e_emb(indices=14541 ,  **get_emb_weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48362e27-6ec7-4213-bf59-59c70ab767f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.81507301e-02,  1.65457201e+00, -7.29150295e-01, -9.72482383e-01,\n",
       "        2.50903666e-01,  5.15618622e-01,  1.44718575e+00, -2.80199870e-02,\n",
       "       -5.34180105e-01,  1.22995472e+00,  7.82899797e-01, -1.07642543e+00,\n",
       "       -5.79468489e-01,  9.34254825e-02, -3.48847717e-01, -5.45396924e-01,\n",
       "        8.11276674e-01, -2.31555760e-01,  2.92052571e-02,  7.11219311e-02,\n",
       "        8.83849204e-01, -1.52462626e+00, -4.19762358e-02,  5.02303600e-01,\n",
       "        4.77711946e-01,  1.19224489e+00, -9.69938993e-01,  1.65196776e+00,\n",
       "       -7.17873045e-04, -1.09269857e-01, -4.43713933e-01, -1.52361952e-02,\n",
       "        7.61415601e-01,  2.26736903e+00,  1.36820400e+00,  4.95398253e-01,\n",
       "        4.06732969e-02,  5.34399927e-01, -3.97180796e-01,  1.50779915e+00,\n",
       "       -1.47803366e+00,  1.60024881e-01,  2.75863390e-02, -8.14473867e-01,\n",
       "       -1.23271143e+00,  1.47423863e+00, -2.29464129e-01,  1.29794729e+00,\n",
       "       -8.18897188e-01,  1.58943796e+00, -4.32124257e-01,  2.78536499e-01,\n",
       "       -1.52678952e-01, -8.66038084e-01, -4.46675926e-01, -1.62731564e+00,\n",
       "        7.88002193e-01, -3.55777115e-01,  1.23571682e+00, -8.07388723e-01,\n",
       "       -2.57213861e-01, -3.37404199e-02, -1.42911839e+00, -7.04018593e-01,\n",
       "       -4.04204100e-01,  7.14555681e-01,  1.01320222e-01, -6.60817266e-01,\n",
       "       -1.21146984e-01, -1.99853420e+00,  1.29373118e-01, -3.96762729e-01,\n",
       "        4.28290665e-01, -3.30418319e-01,  1.31614244e+00,  1.91742942e-01,\n",
       "       -9.19037044e-01,  3.75477701e-01,  5.16400039e-01,  1.09129751e+00,\n",
       "       -9.78969097e-01, -1.43823826e+00, -8.08458984e-01,  3.34758282e-01,\n",
       "       -1.91899264e+00,  8.30730855e-01,  8.39271247e-01,  1.00423539e+00,\n",
       "       -4.66819525e-01, -4.89167273e-01, -1.00505149e+00, -7.28380531e-02,\n",
       "       -5.98257780e-01, -1.48033053e-01,  7.20691204e-01, -1.74390483e+00,\n",
       "        7.38147497e-02,  1.17862260e+00, -7.48750687e-01,  1.77915478e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None 值 rel 會有權重\n",
    "get_r_emb(indices=237 ,  **get_emb_weights )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae375c8e-2bf6-4a96-83a9-84e745a2914f",
   "metadata": {},
   "source": [
    "# 成效計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc8736d0-90b8-4cfe-a582-c5b469b072e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = h+r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb60f26-020a-4e6d-954c-dbfcb6b293ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c30175-6e2b-45a8-96e0-f5863008942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20466, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "464884da-af30-4e55-aba4-987c3b13d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = t.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeb7298f-88af-4960-b732-bcda410933fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先把T的向量製作成df\n",
    "df_t = pd.DataFrame()\n",
    "df_t['t'] = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaff15c1-1fb1-440d-9d0d-1fe05ff1f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 透過lambda 方式 ，一次性計算所有的distance\n",
    "df_t['cosine_distance'] = df_t.t.apply(lambda x : cosine_similarity(  pred  , [x ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39ed480a-8a34-45ff-a01f-0e74258f3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_fun(h): # 計算好的distance 由小到大進行排序\n",
    "    h = np.array( h  ).reshape(-1,).tolist() # 減掉一個dims  [[1],[2],[3]] -> [1,2,3]\n",
    "    my_dict = dict( list(enumerate(np.sort(h)[::-1])) )\n",
    "    h_dict =  dict(zip(my_dict.values(), my_dict.keys()))\n",
    "    # for i,j in enumerate(np.sort(h)[::-1]): # 將排序的結果冠上index後再 進行mapping\n",
    "    #     h_dict[j] = i\n",
    "    return [h_dict[i] for i in h ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6bd4611-3598-4f91-9135-eeffd48488f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_t['rank'] =  df_t['cosine_distance'].apply( lambda x : sort_fun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4aa64c4-e278-407b-95af-485db345243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 成效計算\n",
    "rank_mean = []  \n",
    "for i in range(len(df_t)):\n",
    "    x = df_t.iloc[i]['rank']\n",
    "    rank_mean.append(x[i]) # 因為是對角地所以才用df_t[i][i]計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7572f2-a347-449b-b951-c14da07a4dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453.14961399394116"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#平均分數\n",
    "np.mean( rank_mean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22736d5c-6a36-4e69-a493-0d11ba4751b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20466"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 總長度數\n",
    "len(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a30d5c71-a357-4e08-aede-6d5c3e3dcca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022141581842760733"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均排除了98%的entity\n",
    "np.mean( rank_mean ) / len(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce590e64-bf28-464f-8c49-36f927e798df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_t.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ba2c33d-420e-46a1-9ddc-fba3dfab29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.columns = ['ent_index', 't', 'cosine_distance', 'rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "008ea943-1ce6-47f7-b2d1-d2ddf9e9eee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_index</th>\n",
       "      <th>t</th>\n",
       "      <th>cosine_distance</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.13216862082481384, -0.046637676656246185, ...</td>\n",
       "      <td>[[0.9303413390262458], [-0.0343790433947064], ...</td>\n",
       "      <td>[51, 12794, 16458, 12450, 12450, 9841, 11012, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.07238393276929855, -0.15301825106143951, -0...</td>\n",
       "      <td>[[0.0014534614623641431], [0.9651918395564838]...</td>\n",
       "      <td>[7982, 161, 12537, 3998, 3998, 10219, 9432, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.1519051343202591, -0.08208147436380386, 0....</td>\n",
       "      <td>[[-0.2995563647446651], [-0.12159386912620143]...</td>\n",
       "      <td>[19809, 14328, 756, 5722, 5722, 14556, 17147, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ent_index                                                  t  \\\n",
       "0          0  [-0.13216862082481384, -0.046637676656246185, ...   \n",
       "1          1  [0.07238393276929855, -0.15301825106143951, -0...   \n",
       "2          2  [-0.1519051343202591, -0.08208147436380386, 0....   \n",
       "\n",
       "                                     cosine_distance  \\\n",
       "0  [[0.9303413390262458], [-0.0343790433947064], ...   \n",
       "1  [[0.0014534614623641431], [0.9651918395564838]...   \n",
       "2  [[-0.2995563647446651], [-0.12159386912620143]...   \n",
       "\n",
       "                                                rank  \n",
       "0  [51, 12794, 16458, 12450, 12450, 9841, 11012, ...  \n",
       "1  [7982, 161, 12537, 3998, 3998, 10219, 9432, 15...  \n",
       "2  [19809, 14328, 756, 5722, 5722, 14556, 17147, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92afab-3a2b-46f7-99fd-7d274562f915",
   "metadata": {},
   "source": [
    "# Predict : 第N筆資料 h + r => reutrn前N筆數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8d605ad1-dc15-45a8-a21b-45cb8805056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moder_predict_by_row(df , row_num , top_n):\n",
    "\n",
    "    return df['rank'].apply(lambda x : x[row_num] ).sort_values().index[:top_n].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9927e180-486e-48d9-aa6f-c80122aa7cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6592, 11535, 13060]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moder_predict_by_row(df =df_t  , row_num = 1657, top_n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b4a8dc-875a-457b-bc4f-0669ff13c408",
   "metadata": {},
   "source": [
    "# 輸入pred 數值，回傳最接近的entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "616de3b2-ab99-4f79-bc04-1fdef8d6108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(pred_value ,entity_emb_w ,top_n ):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['var'] = entity_emb_w.tolist()\n",
    "    df['var_dis'] = df['var'].apply(lambda x :cosine_similarity( [x],[ pred_value])[0][0] )\n",
    "    return df.sort_values('var_dis',ascending=False).head(top_n).index.tolist()  \n",
    "            #df.sort_values('var_dis',ascending=False).head(top_n).var_dis.tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1f2bdd4f-f2c3-44dd-9cf0-e0f071ad28a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10543, 4353, 5287, 13397]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = h + r\n",
    "model_predict(pred[0]  ,e_emb_w ,top_n = 4 ) # pred結果去跟所有向量排序，並依照大小，找出最像似的前4個人\\[[[[[[[[[[[[[]]]]]]]]]]]]]]ㄣ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "857d44bc-a940-4fa8-9ed1-ed4c07774dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13397, 4353, 13443, 10543]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict(t[0]  ,e_emb_w ,top_n = 4 ) # 答案t向量去排序離他最近的幾個人，發現到pred的第四個才是正確答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8dafdefc-aced-4447-96b0-b191203091cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000000000004,\n",
       " 0.9926496947435993,\n",
       " 0.9924586673716429,\n",
       " 0.9917024273408873]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict(t[0]  ,e_emb_w ,top_n = 4 ) # 答案t向量去排序離他最近的幾個人，並評估向量相似度，可看前幾個都方常接近"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
